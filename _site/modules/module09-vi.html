<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.26">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Module 9: Variational Inference – Bayesian Statistics and Inference</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-587c61ba64f3a5504c4d52d930310e48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-b337f537912f5ab074b938eebad4c5d7.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-sidebar docked nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Bayesian Statistics and Inference</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link active" href="../index.html" aria-current="page"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../syllabus.html"> 
<span class="menu-text">Syllabus</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-modules" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Modules</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-modules">    
        <li>
    <a class="dropdown-item" href="../modules/module01-foundations.html">
 <span class="dropdown-text">1. Foundations of Bayesian Inference</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../modules/module02-conjugate.html">
 <span class="dropdown-text">2. Conjugate Models and Exact Inference</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../modules/module03-regression.html">
 <span class="dropdown-text">3. Bayesian Regression</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../modules/module04-glm.html">
 <span class="dropdown-text">4. Bayesian GLMs</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../modules/module05-mcmc-theory.html">
 <span class="dropdown-text">5. MCMC Theory</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../modules/module06-mh.html">
 <span class="dropdown-text">6. Metropolis-Hastings</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../modules/module07-gibbs.html">
 <span class="dropdown-text">7. Gibbs Sampling</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../modules/module08-advanced-mcmc.html">
 <span class="dropdown-text">8. Advanced MCMC</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../modules/module09-vi.html">
 <span class="dropdown-text">9. Variational Inference</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../modules/module10-gp.html">
 <span class="dropdown-text">10. Gaussian Processes</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../modules/module11-optimization.html">
 <span class="dropdown-text">11. Optimization</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../modules/module12-asymptotics.html">
 <span class="dropdown-text">12. Asymptotics and Consistency</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../modules/module13-checking.html">
 <span class="dropdown-text">13. Model Checking and Criticism</span></a>
  </li>  
    </ul>
  </li>
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../modules/module01-foundations.html">Modules</a></li><li class="breadcrumb-item"><a href="../modules/module09-vi.html">Module 9: Variational Inference</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Bayesian Statistics and Inference</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../syllabus.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Syllabus</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Modules</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../modules/module01-foundations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Module 1: Foundations of Bayesian Inference</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../modules/module02-conjugate.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Module 2: Conjugate Models and Exact Inference</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../modules/module03-regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Module 3: Bayesian Regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../modules/module04-glm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Module 4: Bayesian Generalized Linear Models</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../modules/module05-mcmc-theory.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Module 5: Markov Chain Monte Carlo (MCMC) Theory</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../modules/module06-mh.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Module 6: Metropolis–Hastings Algorithm</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../modules/module07-gibbs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Module 7: Gibbs Sampling</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../modules/module08-advanced-mcmc.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Module 8: Advanced MCMC Methods</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../modules/module09-vi.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Module 9: Variational Inference</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../modules/module10-gp.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Module 10: Gaussian Processes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../modules/module11-optimization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Module 11: Optimization in Bayesian Inference</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../modules/module12-asymptotics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Module 12: Asymptotic Theory and Consistency</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../modules/module13-checking.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Module 13: Model Checking and Criticism</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#module-9-variational-inference" id="toc-module-9-variational-inference" class="nav-link active" data-scroll-target="#module-9-variational-inference">Module 9: Variational Inference</a>
  <ul class="collapse">
  <li><a href="#kl-divergence-and-the-elbo" id="toc-kl-divergence-and-the-elbo" class="nav-link" data-scroll-target="#kl-divergence-and-the-elbo">1. KL Divergence and the ELBO</a>
  <ul class="collapse">
  <li><a href="#kl-divergence-measure-theoretic-definition" id="toc-kl-divergence-measure-theoretic-definition" class="nav-link" data-scroll-target="#kl-divergence-measure-theoretic-definition">1.1 KL Divergence: Measure-Theoretic Definition</a></li>
  <li><a href="#posterior-approximation-and-definition-of-the-elbo" id="toc-posterior-approximation-and-definition-of-the-elbo" class="nav-link" data-scroll-target="#posterior-approximation-and-definition-of-the-elbo">1.2 Posterior Approximation and Definition of the ELBO</a></li>
  </ul></li>
  <li><a href="#mean-field-variational-families" id="toc-mean-field-variational-families" class="nav-link" data-scroll-target="#mean-field-variational-families">2. Mean-Field Variational Families</a>
  <ul class="collapse">
  <li><a href="#factorization-assumption" id="toc-factorization-assumption" class="nav-link" data-scroll-target="#factorization-assumption">2.1 Factorization Assumption</a></li>
  <li><a href="#coordinate-ascent-variational-inference-cavi" id="toc-coordinate-ascent-variational-inference-cavi" class="nav-link" data-scroll-target="#coordinate-ascent-variational-inference-cavi">2.2 Coordinate Ascent Variational Inference (CAVI)</a></li>
  <li><a href="#exponential-family-vi" id="toc-exponential-family-vi" class="nav-link" data-scroll-target="#exponential-family-vi">2.3 Exponential Family VI</a></li>
  </ul></li>
  <li><a href="#variational-inference-in-a-conjugate-normalnormal-model" id="toc-variational-inference-in-a-conjugate-normalnormal-model" class="nav-link" data-scroll-target="#variational-inference-in-a-conjugate-normalnormal-model">3. Variational Inference in a Conjugate Normal–Normal Model</a>
  <ul class="collapse">
  <li><a href="#model-and-exact-posterior" id="toc-model-and-exact-posterior" class="nav-link" data-scroll-target="#model-and-exact-posterior">3.1 Model and Exact Posterior</a></li>
  <li><a href="#mean-field-approximation-with-redundant-factorization" id="toc-mean-field-approximation-with-redundant-factorization" class="nav-link" data-scroll-target="#mean-field-approximation-with-redundant-factorization">3.2 Mean-Field Approximation with Redundant Factorization</a></li>
  </ul></li>
  <li><a href="#comparison-with-mcmc-bias-variance-and-asymptotics" id="toc-comparison-with-mcmc-bias-variance-and-asymptotics" class="nav-link" data-scroll-target="#comparison-with-mcmc-bias-variance-and-asymptotics">4. Comparison with MCMC: Bias, Variance, and Asymptotics</a>
  <ul class="collapse">
  <li><a href="#biasvariance-tradeoff" id="toc-biasvariance-tradeoff" class="nav-link" data-scroll-target="#biasvariance-tradeoff">4.1 Bias–Variance Tradeoff</a></li>
  <li><a href="#failure-modes-of-vi" id="toc-failure-modes-of-vi" class="nav-link" data-scroll-target="#failure-modes-of-vi">4.2 Failure Modes of VI</a></li>
  </ul></li>
  <li><a href="#problem-set-9-representative-problems" id="toc-problem-set-9-representative-problems" class="nav-link" data-scroll-target="#problem-set-9-representative-problems">5. Problem Set 9 (Representative Problems)</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../modules/module01-foundations.html">Modules</a></li><li class="breadcrumb-item"><a href="../modules/module09-vi.html">Module 9: Variational Inference</a></li></ol></nav>
<div class="quarto-title">
<h1 class="title">Module 9: Variational Inference</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="module-9-variational-inference" class="level1">
<h1>Module 9: Variational Inference</h1>
<p>This module develops variational inference (VI) as an optimization-based approximation to Bayesian inference. We treat VI as a problem of <strong>projecting</strong> the posterior distribution onto a restricted family of distributions by minimizing a divergence functional. The exposition is measure-theoretic and emphasizes:</p>
<ul>
<li>the functional-analytic properties of the Kullback–Leibler divergence,</li>
<li>the ELBO (evidence lower bound) as a variational characterization of the marginal likelihood,</li>
<li>the structure of mean-field families and coordinate ascent variational inference (CAVI), and</li>
<li>the relationship between VI and MCMC in terms of bias, variance, and asymptotics.</li>
</ul>
<section id="kl-divergence-and-the-elbo" class="level2">
<h2 class="anchored" data-anchor-id="kl-divergence-and-the-elbo">1. KL Divergence and the ELBO</h2>
<p>We work on a measurable parameter space <span class="math inline">\(\bigl(\Theta, \mathcal{T}\bigr)\)</span> with a <span class="math inline">\(\sigma\)</span>-finite reference measure <span class="math inline">\(\nu\)</span> (typically Lebesgue measure on <span class="math inline">\(\mathbb{R}^d\)</span>). All densities below are understood with respect to <span class="math inline">\(\nu\)</span>.</p>
<section id="kl-divergence-measure-theoretic-definition" class="level3">
<h3 class="anchored" data-anchor-id="kl-divergence-measure-theoretic-definition">1.1 KL Divergence: Measure-Theoretic Definition</h3>
<p>Let <span class="math inline">\(P\)</span> and <span class="math inline">\(Q\)</span> be probability measures on <span class="math inline">\(\bigl(\Theta, \mathcal{T}\bigr)\)</span>. Assume that</p>
<p><span class="math display">\[
Q \ll P,
\]</span></p>
<p>so that the Radon–Nikodym derivative <span class="math inline">\(\frac{dQ}{dP}\)</span> exists. The <strong>Kullback–Leibler divergence</strong> from <span class="math inline">\(Q\)</span> to <span class="math inline">\(P\)</span> is</p>
<p><span class="math display">\[
\operatorname{KL}(Q \Vert P)
  := \int_\Theta \log\Bigl( \frac{dQ}{dP}(\theta) \Bigr) \, Q(d\theta)
  = \int_\Theta \frac{dQ}{dP}(\theta) \log\Bigl( \frac{dQ}{dP}(\theta) \Bigr) \, P(d\theta),
\]</span></p>
<p>with the convention that <span class="math inline">\(a \log a = 0\)</span> at <span class="math inline">\(a=0\)</span> and that <span class="math inline">\(\operatorname{KL}(Q \Vert P) = +\infty\)</span> if <span class="math inline">\(Q \not\ll P\)</span>.</p>
<p>In the common case where <span class="math inline">\(P\)</span> and <span class="math inline">\(Q\)</span> admit densities <span class="math inline">\(p\)</span> and <span class="math inline">\(q\)</span> with respect to <span class="math inline">\(\nu\)</span>, we write</p>
<p><span class="math display">\[
\operatorname{KL}(q \Vert p)
  = \int_\Theta q(\theta) \log \frac{q(\theta)}{p(\theta)} \, \nu(d\theta).
\]</span></p>
<p><strong>Basic properties.</strong> Under mild integrability assumptions:</p>
<ul>
<li><span class="math inline">\(\operatorname{KL}(Q \Vert P) \ge 0\)</span>,</li>
<li><span class="math inline">\(\operatorname{KL}(Q \Vert P) = 0\)</span> if and only if <span class="math inline">\(Q = P\)</span> (as measures),</li>
<li><span class="math inline">\(Q \mapsto \operatorname{KL}(Q \Vert P)\)</span> is convex.</li>
</ul>
<p>These follow from Jensen’s inequality applied to the convex function <span class="math inline">\(x \mapsto x \log x\)</span>.</p>
</section>
<section id="posterior-approximation-and-definition-of-the-elbo" class="level3">
<h3 class="anchored" data-anchor-id="posterior-approximation-and-definition-of-the-elbo">1.2 Posterior Approximation and Definition of the ELBO</h3>
<p>Let <span class="math inline">\(x\)</span> denote observed data. Write the joint density</p>
<p><span class="math display">\[
p(\theta, x) = p(x \mid \theta)\, p(\theta),
\]</span></p>
<p>and suppose the posterior density exists,</p>
<p><span class="math display">\[
p(\theta \mid x) = \frac{p(\theta, x)}{p(x)}, \quad
p(x) = \int p(\theta, x)\, d\theta.
\]</span></p>
<p>Let <span class="math inline">\(\mathcal{Q}\)</span> be a family of candidate densities <span class="math inline">\(q(\theta)\)</span> (with respect to the same reference measure). <strong>Variational inference</strong> chooses</p>
<p><span class="math display">\[
q^* \in \arg\min_{q \in \mathcal{Q}} \operatorname{KL}\bigl(q \Vert p(\cdot \mid x)\bigr).
\]</span></p>
<p>Direct optimization of <span class="math inline">\(\operatorname{KL}(q \Vert p(\cdot \mid x))\)</span> is often inconvenient because it involves the (intractable) posterior density. We therefore introduce the <strong>evidence lower bound (ELBO)</strong>,</p>
<p><span class="math display">\[
\mathcal{L}(q) := \int q(\theta) \log \frac{p(\theta, x)}{q(\theta)} \, d\theta
                = \mathbb{E}_q\bigl[ \log p(\theta, x) \bigr]
                  - \mathbb{E}_q\bigl[ \log q(\theta) \bigr].
\]</span></p>
<p>We will show that maximizing <span class="math inline">\(\mathcal{L}(q)\)</span> is equivalent to minimizing <span class="math inline">\(\operatorname{KL}\bigl(q \Vert p(\cdot \mid x)\bigr)\)</span>.</p>
<div class="theorem">
<p><strong>Theorem 9.1 (ELBO–KL Decomposition).</strong></p>
<p>For any density <span class="math inline">\(q\)</span> such that <span class="math inline">\(\operatorname{KL}\bigl(q \Vert p(\cdot \mid x)\bigr) &lt; \infty\)</span>, we have</p>
<p><span class="math display">\[
\log p(x) = \mathcal{L}(q)
             + \operatorname{KL}\bigl(q \Vert p(\cdot \mid x)\bigr).
\]</span></p>
<p>In particular, <span class="math inline">\(\mathcal{L}(q) \le \log p(x)\)</span>, with equality if and only if <span class="math inline">\(q = p(\cdot \mid x)\)</span> almost everywhere.</p>
<p><em>Proof.</em> By definition of KL divergence between <span class="math inline">\(q\)</span> and the posterior, <span class="math display">\[
\operatorname{KL}\bigl(q \Vert p(\cdot \mid x)\bigr)
  = \int q(\theta)
       \log \frac{q(\theta)}{p(\theta \mid x)}\, d\theta.
\]</span> Using Bayes’ rule <span class="math inline">\(p(\theta \mid x) = p(\theta, x)/p(x)\)</span>, <span class="math display">\[
\log \frac{q(\theta)}{p(\theta \mid x)}
  = \log q(\theta)
    - \log p(\theta,x)
    + \log p(x).
\]</span> Substitute into the KL expression and integrate termwise: <span class="math display">\[
\begin{aligned}
\operatorname{KL}\bigl(q \Vert p(\cdot \mid x)\bigr)
&amp;= \int q(\theta) \log q(\theta)\, d\theta
    - \int q(\theta) \log p(\theta,x)\, d\theta
    + \int q(\theta) \log p(x)\, d\theta \\
&amp;= \mathbb{E}_q[\log q(\theta)]
    - \mathbb{E}_q[\log p(\theta,x)]
    + \log p(x) \int q(\theta)\, d\theta.
\end{aligned}
\]</span> Since <span class="math inline">\(q\)</span> is a density, the last integral equals 1. Rearranging gives <span class="math display">\[
\log p(x)
  = \underbrace{\mathbb{E}_q[\log p(\theta,x)]
                 - \mathbb{E}_q[\log q(\theta)]}_{\mathcal{L}(q)}
    + \operatorname{KL}\bigl(q \Vert p(\cdot \mid x)\bigr),
\]</span> which is the claimed identity.</p>
<p>The inequality <span class="math inline">\(\mathcal{L}(q) \le \log p(x)\)</span> follows from nonnegativity of the KL divergence. Equality holds if and only if <span class="math inline">\(\operatorname{KL}\bigl(q \Vert p(\cdot \mid x)\bigr) = 0\)</span>, i.e., <span class="math inline">\(q = p(\cdot \mid x)\)</span> almost everywhere. <span class="math inline">\(\square\)</span></p>
</div>
<p>Thus, <strong>maximizing the ELBO is equivalent to minimizing the KL divergence to the posterior</strong> within the chosen family <span class="math inline">\(\mathcal{Q}\)</span>.</p>
</section>
</section>
<section id="mean-field-variational-families" class="level2">
<h2 class="anchored" data-anchor-id="mean-field-variational-families">2. Mean-Field Variational Families</h2>
<p>We now restrict to a tractable family <span class="math inline">\(\mathcal{Q}\)</span> of candidate densities. A common choice is the <strong>mean-field family</strong>, which assumes conditional independence between groups of parameters under <span class="math inline">\(q\)</span>.</p>
<section id="factorization-assumption" class="level3">
<h3 class="anchored" data-anchor-id="factorization-assumption">2.1 Factorization Assumption</h3>
<p>Partition <span class="math inline">\(\theta\)</span> into blocks</p>
<p><span class="math display">\[
\theta = (\theta_1, \dots, \theta_J),
\]</span></p>
<p>where each <span class="math inline">\(\theta_j\)</span> takes values in some measurable space <span class="math inline">\((\Theta_j, \mathcal{T}_j)\)</span>. The <strong>mean-field variational family</strong> is</p>
<p><span class="math display">\[
\mathcal{Q}_{\text{MF}}
  := \Bigl\{ q(\theta) = \prod_{j=1}^J q_j(\theta_j)
                  : q_j \text{ densities on } \Theta_j \Bigr\}.
\]</span></p>
<p>The factorization is an approximation: in general, the true posterior <span class="math inline">\(p(\theta \mid x)\)</span> does not factorize in this way, so VI introduces dependence-structure bias.</p>
</section>
<section id="coordinate-ascent-variational-inference-cavi" class="level3">
<h3 class="anchored" data-anchor-id="coordinate-ascent-variational-inference-cavi">2.2 Coordinate Ascent Variational Inference (CAVI)</h3>
<p>We wish to solve the constrained optimization problem</p>
<p><span class="math display">\[
\max_{q_1,\dots,q_J}\, \mathcal{L}(q)
  \quad \text{subject to}\quad
  q(\theta) = \prod_{j=1}^J q_j(\theta_j), \;
  q_j \ge 0, \; \int q_j(\theta_j)\, d\theta_j = 1.
\]</span></p>
<p>Exact joint optimization is often difficult, but we can use <strong>coordinate ascent</strong>: repeatedly optimize <span class="math inline">\(\mathcal{L}(q)\)</span> with respect to a single factor <span class="math inline">\(q_j\)</span>, holding the others fixed. The optimal <span class="math inline">\(q_j\)</span> has a closed form.</p>
<div class="theorem">
<p><strong>Theorem 9.2 (Optimal Mean-Field Factor Updates).</strong></p>
<p>Fix <span class="math inline">\(q_{-j}(\theta_{-j}) = \prod_{k \ne j} q_k(\theta_k)\)</span> and consider <span class="math inline">\(q_j\)</span> varying over densities on <span class="math inline">\(\Theta_j\)</span>. Then, up to multiplicative normalization,</p>
<p><span class="math display">\[
\log q_j^*(\theta_j)
  = \mathbb{E}_{q_{-j}}[\log p(\theta, x)] + \text{constant},
\]</span></p>
<p>or equivalently,</p>
<p><span class="math display">\[
q_j^*(\theta_j)
  \propto \exp\Bigl(\mathbb{E}_{q_{-j}}[\log p(\theta, x)]\Bigr).
\]</span></p>
<p><em>Proof.</em> Write the ELBO as <span class="math display">\[
\mathcal{L}(q)
  = \mathbb{E}_q[\log p(\theta,x)]
    - \mathbb{E}_q[\log q(\theta)].
\]</span> Under the mean-field factorization <span class="math inline">\(q(\theta) = q_j(\theta_j) q_{-j}(\theta_{-j})\)</span>, we can group terms depending on <span class="math inline">\(q_j\)</span> and those independent of <span class="math inline">\(q_j\)</span>.</p>
<p>First term: <span class="math display">\[
\mathbb{E}_q[\log p(\theta,x)]
  = \int q_j(\theta_j)\, \mathbb{E}_{q_{-j}}[\log p(\theta,x)]\, d\theta_j.
\]</span></p>
<p>Second term (entropy part): <span class="math display">\[
\mathbb{E}_q[\log q(\theta)]
  = \mathbb{E}_q\bigl[\log q_j(\theta_j)\bigr]
    + \mathbb{E}_q\bigl[\log q_{-j}(\theta_{-j})\bigr].
\]</span> The second expectation does not depend on <span class="math inline">\(q_j\)</span> and can be treated as constant. Hence, up to an additive constant independent of <span class="math inline">\(q_j\)</span>, the ELBO as a functional of <span class="math inline">\(q_j\)</span> is <span class="math display">\[
\mathcal{L}_j(q_j)
  = \int q_j(\theta_j)
        \mathbb{E}_{q_{-j}}[\log p(\theta,x)]\, d\theta_j
    - \int q_j(\theta_j) \log q_j(\theta_j)\, d\theta_j.
\]</span></p>
<p>We must maximize <span class="math inline">\(\mathcal{L}_j(q_j)\)</span> over all densities <span class="math inline">\(q_j\)</span> on <span class="math inline">\(\Theta_j\)</span>. This is a <strong>functional optimization problem</strong> with a normalization constraint <span class="math inline">\(\int q_j(\theta_j) d\theta_j = 1\)</span>. Introduce a Lagrange multiplier <span class="math inline">\(\lambda\)</span> and consider the Lagrangian <span class="math display">\[
\mathcal{F}(q_j)
  = \mathcal{L}_j(q_j)
    + \lambda\Bigl( \int q_j(\theta_j) d\theta_j - 1 \Bigr).
\]</span></p>
<p>Taking a first variation in the direction of an arbitrary perturbation <span class="math inline">\(h\)</span> with <span class="math inline">\(\int h(\theta_j) d\theta_j = 0\)</span> and using Gâteaux derivatives, we obtain <span class="math display">\[
\delta \mathcal{F} = \int h(\theta_j)
  \Bigl( \mathbb{E}_{q_{-j}}[\log p(\theta,x)]
         - (1 + \log q_j(\theta_j))
         + \lambda \Bigr) d\theta_j.
\]</span> At an optimum, <span class="math inline">\(\delta \mathcal{F} = 0\)</span> for all such <span class="math inline">\(h\)</span>, which implies that the term in parentheses must vanish almost everywhere: <span class="math display">\[
\mathbb{E}_{q_{-j}}[\log p(\theta,x)]
  - (1 + \log q_j^*(\theta_j))
  + \lambda = 0.
\]</span> Solving for <span class="math inline">\(\log q_j^*(\theta_j)\)</span> gives <span class="math display">\[
\log q_j^*(\theta_j)
  = \mathbb{E}_{q_{-j}}[\log p(\theta,x)]
    + (\lambda - 1).
\]</span> The constant <span class="math inline">\((\lambda - 1)\)</span> enforces normalization and does not depend on <span class="math inline">\(\theta_j\)</span>, so we write simply <span class="math display">\[
\log q_j^*(\theta_j) = \mathbb{E}_{q_{-j}}[\log p(\theta,x)] + C,
\]</span> with <span class="math inline">\(C\)</span> a constant. Exponentiating both sides and renormalizing yields the stated form. <span class="math inline">\(\square\)</span></p>
</div>
<p>This theorem is the basis of <strong>coordinate ascent variational inference (CAVI)</strong>: at each step, replace <span class="math inline">\(q_j\)</span> by <span class="math inline">\(q_j^*\)</span> while holding <span class="math inline">\(q_{-j}\)</span> fixed.</p>
</section>
<section id="exponential-family-vi" class="level3">
<h3 class="anchored" data-anchor-id="exponential-family-vi">2.3 Exponential Family VI</h3>
<p>Suppose the joint density <span class="math inline">\(p(\theta,x)\)</span> belongs to an exponential family of the form</p>
<p><span class="math display">\[
\log p(\theta,x) = \eta(x)^\top T(\theta) - A(\eta(x)) + c(x),
\]</span></p>
<p>and suppose each factor <span class="math inline">\(q_j\)</span> is restricted to an exponential family with natural parameters <span class="math inline">\(\lambda_j\)</span>. Then the expectation <span class="math inline">\(\mathbb{E}_{q_{-j}}[\log p(\theta,x)]\)</span> is often linear in sufficient statistics of <span class="math inline">\(\theta_j\)</span>, implying that <span class="math inline">\(q_j^*\)</span> remains in the same exponential family with updated natural parameters determined by expectations under <span class="math inline">\(q_{-j}\)</span>. This yields closed-form CAVI updates.</p>
</section>
</section>
<section id="variational-inference-in-a-conjugate-normalnormal-model" class="level2">
<h2 class="anchored" data-anchor-id="variational-inference-in-a-conjugate-normalnormal-model">3. Variational Inference in a Conjugate Normal–Normal Model</h2>
<p>We now work out a concrete example to illustrate VI computations and compare them to exact Bayesian inference.</p>
<section id="model-and-exact-posterior" class="level3">
<h3 class="anchored" data-anchor-id="model-and-exact-posterior">3.1 Model and Exact Posterior</h3>
<p>Consider a Normal–Normal model with known variance:</p>
<p><span class="math display">\[
Y_i \mid \theta \;\sim\; N(\theta, \sigma^2), \quad i=1,\dots,n, \quad
\theta \sim N(m_0, v_0),
\]</span></p>
<p>with <span class="math inline">\(\sigma^2 &gt; 0\)</span>, <span class="math inline">\(v_0 &gt; 0\)</span> known. The posterior is exactly Normal,</p>
<p><span class="math display">\[
\theta \mid y_{1:n} \sim N(m_n, v_n),
\]</span></p>
<p>where</p>
<p><span class="math display">\[
v_n^{-1} = v_0^{-1} + \frac{n}{\sigma^2},
\qquad
m_n = v_n\Bigl( v_0^{-1} m_0 + \frac{n \bar{y}}{\sigma^2} \Bigr),
\qquad
\bar{y} = \frac{1}{n} \sum_{i=1}^n y_i.
\]</span></p>
<p>This is a conjugate setting, so VI is not necessary for tractability; however, it provides a clean sanity check.</p>
</section>
<section id="mean-field-approximation-with-redundant-factorization" class="level3">
<h3 class="anchored" data-anchor-id="mean-field-approximation-with-redundant-factorization">3.2 Mean-Field Approximation with Redundant Factorization</h3>
<p>Introduce an artificial factorization by writing <span class="math inline">\(\theta = (\theta_1, \theta_2)\)</span> with the constraint <span class="math inline">\(\theta_1 = \theta_2\)</span> under the true model. Suppose we approximate the posterior with a mean-field family</p>
<p><span class="math display">\[
q(\theta_1, \theta_2) = q_1(\theta_1) q_2(\theta_2),
\]</span></p>
<p>even though the true posterior does not factorize in this way (it is supported on the diagonal <span class="math inline">\(\theta_1 = \theta_2\)</span>). Applying Theorem 9.2 yields coupled updates for <span class="math inline">\(q_1\)</span> and <span class="math inline">\(q_2\)</span> which, at the optimum, restore the equality <span class="math inline">\(\theta_1 = \theta_2\)</span> in distribution, and the product <span class="math inline">\(q_1 q_2\)</span> recovers the exact posterior density. This example illustrates that mean-field VI can be exact if the factorization is aligned with conditional independence structure implied by the model.</p>
<p>More realistic examples (e.g., multivariate Normal posteriors with non-diagonal covariance) yield <strong>strictly biased</strong> mean-field approximations, which we discuss next.</p>
</section>
</section>
<section id="comparison-with-mcmc-bias-variance-and-asymptotics" class="level2">
<h2 class="anchored" data-anchor-id="comparison-with-mcmc-bias-variance-and-asymptotics">4. Comparison with MCMC: Bias, Variance, and Asymptotics</h2>
<section id="biasvariance-tradeoff" class="level3">
<h3 class="anchored" data-anchor-id="biasvariance-tradeoff">4.1 Bias–Variance Tradeoff</h3>
<p>Let <span class="math inline">\(f(\theta)\)</span> be a posterior integrable functional of interest, and denote</p>
<p><span class="math display">\[
\mu := \mathbb{E}_{p(\cdot \mid x)}[f(\theta)],
\qquad
\mu_{\text{VI}} := \mathbb{E}_{q^*}[f(\theta)].
\]</span></p>
<ul>
<li><p>For an ergodic MCMC algorithm with invariant distribution <span class="math inline">\(p(\cdot \mid x)\)</span> and samples <span class="math inline">\(\theta^{(1)},\dots,\theta^{(N)}\)</span>, the Monte Carlo estimator <span class="math display">\[
\hat{\mu}_N = \frac{1}{N} \sum_{k=1}^N f(\theta^{(k)})
\]</span> satisfies a CLT under conditions from Module 5, <span class="math display">\[
\sqrt{N}(\hat{\mu}_N - \mu) \overset{d}{\to} N(0, \sigma_f^2).
\]</span> Thus, it is (asymptotically) unbiased but has variance <span class="math inline">\(\sigma_f^2 / N\)</span>.</p></li>
<li><p>For VI, the quantity <span class="math inline">\(\mu_{\text{VI}}\)</span> is deterministic once <span class="math inline">\(q^*\)</span> is obtained. There is <strong>no sampling variance</strong>, but in general <span class="math inline">\(\mu_{\text{VI}} \ne \mu\)</span>; the difference <span class="math inline">\(\mu_{\text{VI}} - \mu\)</span> is an approximation <strong>bias</strong> induced by restricting <span class="math inline">\(q\)</span> to <span class="math inline">\(\mathcal{Q}\)</span>.</p></li>
</ul>
<p>In practice, VI trades off bias against computational speed and ease of implementation.</p>
</section>
<section id="failure-modes-of-vi" class="level3">
<h3 class="anchored" data-anchor-id="failure-modes-of-vi">4.2 Failure Modes of VI</h3>
<p>Typical issues include:</p>
<ul>
<li><strong>Underestimation of posterior variance.</strong> Mean-field approximations ignore posterior correlations, which often leads to overly concentrated approximations.</li>
<li><strong>Mode-seeking behavior.</strong> Minimizing <span class="math inline">\(\operatorname{KL}(q \Vert p)\)</span> penalizes placing mass where <span class="math inline">\(p\)</span> is small but is relatively tolerant of missing modes entirely, so VI tends to focus on one mode of a multimodal posterior.</li>
<li><strong>Sensitivity to initialization.</strong> CAVI may converge to local optima of the ELBO in nonconvex problems.</li>
</ul>
<p>These phenomena should be understood and diagnosed when using VI in place of MCMC.</p>
</section>
</section>
<section id="problem-set-9-representative-problems" class="level2">
<h2 class="anchored" data-anchor-id="problem-set-9-representative-problems">5. Problem Set 9 (Representative Problems)</h2>
<ol type="1">
<li><p><strong>ELBO Identity (Measure-Theoretic Proof).</strong> Prove Theorem 9.1 in full generality using probability measures <span class="math inline">\(P\)</span> and <span class="math inline">\(Q\)</span> and Radon–Nikodym derivatives, explicitly checking conditions under which termwise integration and changes of measure are justified.</p></li>
<li><p><strong>CAVI Derivation with Functional Analysis.</strong> Re-derive Theorem 9.2 using functional-analytic language (e.g., viewing the space of densities as a convex subset of <span class="math inline">\(L^1\)</span>), and show that the ELBO is strictly concave in each factor <span class="math inline">\(q_j\)</span> when <span class="math inline">\(p(\theta,x)\)</span> is strictly positive.</p></li>
<li><p><strong>VI in a Conjugate Model.</strong> For the Normal–Normal model with known variance, work out a variational approximation in which <span class="math inline">\(q\)</span> is restricted to a Normal family. Verify that the variational optimum coincides with the exact posterior, and compute the ELBO at the optimum.</p></li>
<li><p><strong>Bias in a Correlated Gaussian Posterior.</strong> Consider a bivariate Normal posterior <span class="math inline">\(N_2(m, \Sigma)\)</span> with nonzero off-diagonal entries. Approximate it by a mean-field product <span class="math inline">\(q(\theta_1,\theta_2) = q_1(\theta_1) q_2(\theta_2)\)</span> with <span class="math inline">\(q_j\)</span> univariate Normals, and explicitly compute <span class="math inline">\(q_1, q_2\)</span> and the resulting approximation error in means and variances.</p></li>
<li><p><strong>VI vs MCMC in High Dimensions.</strong> Consider a high-dimensional Bayesian logistic regression model. Discuss qualitatively and, where possible, quantitatively how VI and MCMC scale with dimension and sample size. In particular, relate the computational complexity of CAVI updates to that of one MCMC sweep (e.g., random-walk MH or HMC), and discuss the implications for bias and variance.</p></li>
</ol>


</section>
</section>

</main> <!-- /main -->
<script src="scripts.js"></script>
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>