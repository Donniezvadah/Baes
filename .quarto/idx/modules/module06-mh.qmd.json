{"title":"Module 6: Metropolis–Hastings Algorithm","markdown":{"yaml":{"title":"Module 6: Metropolis–Hastings Algorithm","page-layout":"article"},"headingText":"Module 6: Metropolis–Hastings Algorithm","containsRefs":false,"markdown":"\n\n\nThis module derives the Metropolis–Hastings (MH) algorithm from detailed balance and analyzes its stationarity, irreducibility, convergence properties, optimal scaling in high dimensions, and common pathologies.\n\n## 1. Construction of the Metropolis–Hastings Kernel\n\n### 1.1 Target and Proposal\n\n- State space: \\((\\mathsf{X}, \\mathcal{X})\\).\n- Target distribution: probability measure \\(\\pi\\) on \\((\\mathsf{X}, \\mathcal{X})\\), with density (possibly unnormalized) \\(\\pi(x)\\) w.r.t. a reference measure \\(\\mu\\).\n- Proposal kernel: \\(q(x, dy)\\), with density \\(q(x,y)\\) w.r.t. \\(\\mu\\).\n\n### 1.2 Acceptance Probability\n\nDefine the acceptance probability\n$$\n \\alpha(x,y) = \\min\\left\\{ 1, \\frac{\\pi(y) q(y,x)}{\\pi(x) q(x,y)} \\right\\}\n$$\nwhen the ratio is well-defined and positive. On sets where \\(\\pi(x) q(x,y) = 0\\), define \\(\\alpha(x,y)\\) appropriately (e.g., 0) to obtain a measurable function.\n\n### 1.3 MH Transition Kernel\n\nThe Metropolis–Hastings transition kernel is\n$$\n K(x, dy) = q(x, dy) \\alpha(x,y) + r(x) \\, \\delta_x(dy),\n$$\nwhere\n$$\n r(x) = 1 - \\int_\\mathsf{X} q(x, dy) \\alpha(x,y)\n$$\nensures that \\(K(x, \\cdot)\\) is a probability measure. Here, \\(\\delta_x\\) denotes the Dirac measure at \\(x\\).\n\n## 2. Detailed Balance and Stationarity\n\n### Theorem 6.1 (Detailed Balance for MH) {#thm-mh-detailed-balance}\n\nAssume that \\(q(x,y) > 0\\) whenever \\(\\pi(x) \\pi(y) > 0\\). Then the MH kernel \\(K\\) satisfies detailed balance with respect to \\(\\pi\\):\n$$\n \\pi(dx) K(x, dy) = \\pi(dy) K(y, dx).\n$$\nIn particular, \\(\\pi\\) is invariant for \\(K\\).\n\n*Proof:* We verify the kernel form of detailed balance,\n$$\n \\pi(dx) K(x, dy) = \\pi(dy) K(y, dx),\n$$\nas equality of measures on \\((\\mathsf{X} \\times \\mathsf{X}, \\mathcal{X} \\otimes \\mathcal{X})\\). By definition,\n$$\n K(x, dy) = q(x, dy) \\alpha(x,y) + r(x) \\, \\delta_x(dy),\n$$\nso\n$$\n \\pi(dx) K(x, dy)\n  = \\pi(dx) q(x, dy) \\alpha(x,y) + \\pi(dx) r(x) \\, \\delta_x(dy).\n$$\nThe second term satisfies\n$$\n \\pi(dx) r(x) \\, \\delta_x(dy) = \\pi(dy) r(y) \\, \\delta_y(dx),\n$$\nwhich is symmetric in \\((x,y)\\) by construction. Thus it remains to check symmetry of the off-diagonal part\n$$\n \\pi(dx) q(x, dy) \\alpha(x,y).\n$$\nOn the product set where \\(\\pi(x) q(x,y) > 0\\) and \\(\\pi(y) q(y,x) > 0\\), the Metropolis–Hastings acceptance probabilities satisfy\n$$\n \\alpha(x,y) = \\min\\left\\{1, \\frac{\\pi(y) q(y,x)}{\\pi(x) q(x,y)} \\right\\},\n \\qquad\n \\alpha(y,x) = \\min\\left\\{1, \\frac{\\pi(x) q(x,y)}{\\pi(y) q(y,x)} \\right\\}.\n$$\nTherefore,\n$$\n \\pi(x) q(x,y) \\alpha(x,y)\n  = \\min\\{ \\pi(x) q(x,y), \\pi(y) q(y,x) \\}\n  = \\pi(y) q(y,x) \\alpha(y,x).\n$$\nSince both sides are densities of the corresponding measures with respect to the product reference measure \\(\\mu(dx) \\, \\mu(dy)\\), we have\n$$\n \\pi(dx) q(x, dy) \\alpha(x,y) = \\pi(dy) q(y, dx) \\alpha(y,x)\n$$\non this set. On the complement where \\(\\pi(x) q(x,y) = 0\\) or \\(\\pi(y) q(y,x) = 0\\), the acceptance probabilities are defined so that each side is zero, so equality still holds. Combining off-diagonal and diagonal parts gives\n$$\n \\pi(dx) K(x, dy) = \\pi(dy) K(y, dx)\n$$\nas measures, i.e., detailed balance. In particular, \\(\\pi\\) is invariant for \\(K\\) by Lemma 5.3. \\(\\square\\)\n\n## 3. Irreducibility, Aperiodicity, and Convergence\n\n### 3.1 Irreducibility\n\nIf the proposal kernel \\(q\\) is \\(\\nu\\)-irreducible on the support of \\(\\pi\\) (for some nontrivial \\(\\nu\\)) and proposals are accepted with positive probability wherever \\(\\pi>0\\), then the MH chain is \\(\\pi\\)-irreducible.\n\n### 3.2 Aperiodicity\n\nMH chains are typically aperiodic provided there is a nonzero probability of remaining at the current state (e.g., via rejection). The self-transition probability \\(r(x)\\) ensures aperiodicity under mild conditions.\n\n### Theorem 6.2 (Convergence to Stationarity) {#thm-mh-convergence}\n\nUnder irreducibility, aperiodicity, and positive recurrence, the MH chain converges in distribution to \\(\\pi\\): for any initial distribution \\(\\mu_0\\),\n$$\n \\| \\mu_0 K^n - \\pi \\|_{\\text{TV}} \\to 0 \\quad \\text{as } n \\to \\infty.\n$$\n\nMoreover, if suitable drift and minorization conditions hold, the convergence is geometric, and ergodic theorems and CLTs apply.\n\n## 4. Optimal Scaling in High Dimensions\n\nConsider a sequence of target distributions \\(\\pi_d\\) on \\(\\mathbb{R}^d\\), e.g., i.i.d. product measures, and random-walk MH with Gaussian proposals of the form\n$$\n Y = X + \\sqrt{\\frac{\\ell^2}{d}} Z, \\quad Z \\sim N_d(0, I_d).\n$$\n\n### Theorem 6.3 (Informal Optimal Scaling Result) {#thm-mh-optimal-scaling}\n\nUnder suitable regularity conditions (e.g., target is product of i.i.d. components with smooth log-density), the rescaled MH chain converges to a diffusion as \\(d \\to \\infty\\). The **optimal acceptance rate** maximizing the speed of this limiting diffusion is approximately\n$$\n \\alpha^* \\approx 0.234.\n$$\n\n*Idea of proof:* Consider the sequence of \\(d\\)-dimensional targets and proposal scales such that the MH chain, linearly interpolated in time and appropriately rescaled, converges in distribution to a limiting Langevin diffusion (diffusion limit). The speed of this limiting diffusion depends on the proposal scale \\(\\ell\\), and one shows that it is maximized when the asymptotic average acceptance probability is approximately 0.234. This involves computing the generator of the limiting diffusion and optimizing its efficiency with respect to \\(\\ell\\).\n\n## 5. Pathologies and Failure Modes\n\n### 5.1 Poorly Tuned Proposals\n\n- **Step size too small:** High acceptance rate but extremely slow exploration (high autocorrelation).\n- **Step size too large:** Very low acceptance rate, many rejections, and poor mixing.\n\n### 5.2 Ill-Conditioned or Multimodal Targets\n\n- Targets with strong correlations or narrow ridges lead to slow mixing of isotropic random-walk proposals.\n- Multimodal targets may trap the chain in one mode for long periods.\n\n### 5.3 Heavy-Tailed Targets\n\nFor targets with heavy tails, random-walk MH may fail to be geometrically ergodic, complicating convergence diagnostics and CLTs.\n\n## 6. Problem Set 6 (Representative Problems)\n\n1. **Detailed Balance for MH.** Prove Theorem @thm-mh-detailed-balance rigorously, including the treatment of sets where \\(\\pi(x) q(x,y) = 0\\) and verifying measurability.\n\n2. **Irreducibility for Random-Walk MH.** For a random-walk MH algorithm on \\(\\mathbb{R}^d\\) with Gaussian proposal and target density strictly positive and continuous on \\(\\mathbb{R}^d\\), prove that the chain is \\(\\pi\\)-irreducible. Explain how this, together with drift and minorization conditions from Module 5 (see Theorem @thm-geom-ergodicity-drift-minorization), leads to convergence as in Theorem @thm-mh-convergence.\n\n3. **Geometric Ergodicity and Heavy Tails.** Consider a target distribution with polynomially decaying tails and a random-walk MH with Gaussian proposals. Investigate whether the chain satisfies a drift condition that implies geometric ergodicity, and relate your findings to the assumptions of Theorem @thm-geom-ergodicity-drift-minorization.\n\n4. **Diffusion Limit Sketch.** Outline the diffusion limit argument leading to the 0.234 optimal acceptance rate for high-dimensional random-walk MH, identifying the main probabilistic tools used, and connect your argument to Theorem @thm-mh-optimal-scaling.\n\n5. **Practical Tuning.** Discuss heuristic rules for tuning proposal variances in MH in finite dimensions and relate them to the high-dimensional scaling theory and the qualitative conclusions of Theorem @thm-mh-optimal-scaling.\n","srcMarkdownNoYaml":"\n\n# Module 6: Metropolis–Hastings Algorithm\n\nThis module derives the Metropolis–Hastings (MH) algorithm from detailed balance and analyzes its stationarity, irreducibility, convergence properties, optimal scaling in high dimensions, and common pathologies.\n\n## 1. Construction of the Metropolis–Hastings Kernel\n\n### 1.1 Target and Proposal\n\n- State space: \\((\\mathsf{X}, \\mathcal{X})\\).\n- Target distribution: probability measure \\(\\pi\\) on \\((\\mathsf{X}, \\mathcal{X})\\), with density (possibly unnormalized) \\(\\pi(x)\\) w.r.t. a reference measure \\(\\mu\\).\n- Proposal kernel: \\(q(x, dy)\\), with density \\(q(x,y)\\) w.r.t. \\(\\mu\\).\n\n### 1.2 Acceptance Probability\n\nDefine the acceptance probability\n$$\n \\alpha(x,y) = \\min\\left\\{ 1, \\frac{\\pi(y) q(y,x)}{\\pi(x) q(x,y)} \\right\\}\n$$\nwhen the ratio is well-defined and positive. On sets where \\(\\pi(x) q(x,y) = 0\\), define \\(\\alpha(x,y)\\) appropriately (e.g., 0) to obtain a measurable function.\n\n### 1.3 MH Transition Kernel\n\nThe Metropolis–Hastings transition kernel is\n$$\n K(x, dy) = q(x, dy) \\alpha(x,y) + r(x) \\, \\delta_x(dy),\n$$\nwhere\n$$\n r(x) = 1 - \\int_\\mathsf{X} q(x, dy) \\alpha(x,y)\n$$\nensures that \\(K(x, \\cdot)\\) is a probability measure. Here, \\(\\delta_x\\) denotes the Dirac measure at \\(x\\).\n\n## 2. Detailed Balance and Stationarity\n\n### Theorem 6.1 (Detailed Balance for MH) {#thm-mh-detailed-balance}\n\nAssume that \\(q(x,y) > 0\\) whenever \\(\\pi(x) \\pi(y) > 0\\). Then the MH kernel \\(K\\) satisfies detailed balance with respect to \\(\\pi\\):\n$$\n \\pi(dx) K(x, dy) = \\pi(dy) K(y, dx).\n$$\nIn particular, \\(\\pi\\) is invariant for \\(K\\).\n\n*Proof:* We verify the kernel form of detailed balance,\n$$\n \\pi(dx) K(x, dy) = \\pi(dy) K(y, dx),\n$$\nas equality of measures on \\((\\mathsf{X} \\times \\mathsf{X}, \\mathcal{X} \\otimes \\mathcal{X})\\). By definition,\n$$\n K(x, dy) = q(x, dy) \\alpha(x,y) + r(x) \\, \\delta_x(dy),\n$$\nso\n$$\n \\pi(dx) K(x, dy)\n  = \\pi(dx) q(x, dy) \\alpha(x,y) + \\pi(dx) r(x) \\, \\delta_x(dy).\n$$\nThe second term satisfies\n$$\n \\pi(dx) r(x) \\, \\delta_x(dy) = \\pi(dy) r(y) \\, \\delta_y(dx),\n$$\nwhich is symmetric in \\((x,y)\\) by construction. Thus it remains to check symmetry of the off-diagonal part\n$$\n \\pi(dx) q(x, dy) \\alpha(x,y).\n$$\nOn the product set where \\(\\pi(x) q(x,y) > 0\\) and \\(\\pi(y) q(y,x) > 0\\), the Metropolis–Hastings acceptance probabilities satisfy\n$$\n \\alpha(x,y) = \\min\\left\\{1, \\frac{\\pi(y) q(y,x)}{\\pi(x) q(x,y)} \\right\\},\n \\qquad\n \\alpha(y,x) = \\min\\left\\{1, \\frac{\\pi(x) q(x,y)}{\\pi(y) q(y,x)} \\right\\}.\n$$\nTherefore,\n$$\n \\pi(x) q(x,y) \\alpha(x,y)\n  = \\min\\{ \\pi(x) q(x,y), \\pi(y) q(y,x) \\}\n  = \\pi(y) q(y,x) \\alpha(y,x).\n$$\nSince both sides are densities of the corresponding measures with respect to the product reference measure \\(\\mu(dx) \\, \\mu(dy)\\), we have\n$$\n \\pi(dx) q(x, dy) \\alpha(x,y) = \\pi(dy) q(y, dx) \\alpha(y,x)\n$$\non this set. On the complement where \\(\\pi(x) q(x,y) = 0\\) or \\(\\pi(y) q(y,x) = 0\\), the acceptance probabilities are defined so that each side is zero, so equality still holds. Combining off-diagonal and diagonal parts gives\n$$\n \\pi(dx) K(x, dy) = \\pi(dy) K(y, dx)\n$$\nas measures, i.e., detailed balance. In particular, \\(\\pi\\) is invariant for \\(K\\) by Lemma 5.3. \\(\\square\\)\n\n## 3. Irreducibility, Aperiodicity, and Convergence\n\n### 3.1 Irreducibility\n\nIf the proposal kernel \\(q\\) is \\(\\nu\\)-irreducible on the support of \\(\\pi\\) (for some nontrivial \\(\\nu\\)) and proposals are accepted with positive probability wherever \\(\\pi>0\\), then the MH chain is \\(\\pi\\)-irreducible.\n\n### 3.2 Aperiodicity\n\nMH chains are typically aperiodic provided there is a nonzero probability of remaining at the current state (e.g., via rejection). The self-transition probability \\(r(x)\\) ensures aperiodicity under mild conditions.\n\n### Theorem 6.2 (Convergence to Stationarity) {#thm-mh-convergence}\n\nUnder irreducibility, aperiodicity, and positive recurrence, the MH chain converges in distribution to \\(\\pi\\): for any initial distribution \\(\\mu_0\\),\n$$\n \\| \\mu_0 K^n - \\pi \\|_{\\text{TV}} \\to 0 \\quad \\text{as } n \\to \\infty.\n$$\n\nMoreover, if suitable drift and minorization conditions hold, the convergence is geometric, and ergodic theorems and CLTs apply.\n\n## 4. Optimal Scaling in High Dimensions\n\nConsider a sequence of target distributions \\(\\pi_d\\) on \\(\\mathbb{R}^d\\), e.g., i.i.d. product measures, and random-walk MH with Gaussian proposals of the form\n$$\n Y = X + \\sqrt{\\frac{\\ell^2}{d}} Z, \\quad Z \\sim N_d(0, I_d).\n$$\n\n### Theorem 6.3 (Informal Optimal Scaling Result) {#thm-mh-optimal-scaling}\n\nUnder suitable regularity conditions (e.g., target is product of i.i.d. components with smooth log-density), the rescaled MH chain converges to a diffusion as \\(d \\to \\infty\\). The **optimal acceptance rate** maximizing the speed of this limiting diffusion is approximately\n$$\n \\alpha^* \\approx 0.234.\n$$\n\n*Idea of proof:* Consider the sequence of \\(d\\)-dimensional targets and proposal scales such that the MH chain, linearly interpolated in time and appropriately rescaled, converges in distribution to a limiting Langevin diffusion (diffusion limit). The speed of this limiting diffusion depends on the proposal scale \\(\\ell\\), and one shows that it is maximized when the asymptotic average acceptance probability is approximately 0.234. This involves computing the generator of the limiting diffusion and optimizing its efficiency with respect to \\(\\ell\\).\n\n## 5. Pathologies and Failure Modes\n\n### 5.1 Poorly Tuned Proposals\n\n- **Step size too small:** High acceptance rate but extremely slow exploration (high autocorrelation).\n- **Step size too large:** Very low acceptance rate, many rejections, and poor mixing.\n\n### 5.2 Ill-Conditioned or Multimodal Targets\n\n- Targets with strong correlations or narrow ridges lead to slow mixing of isotropic random-walk proposals.\n- Multimodal targets may trap the chain in one mode for long periods.\n\n### 5.3 Heavy-Tailed Targets\n\nFor targets with heavy tails, random-walk MH may fail to be geometrically ergodic, complicating convergence diagnostics and CLTs.\n\n## 6. Problem Set 6 (Representative Problems)\n\n1. **Detailed Balance for MH.** Prove Theorem @thm-mh-detailed-balance rigorously, including the treatment of sets where \\(\\pi(x) q(x,y) = 0\\) and verifying measurability.\n\n2. **Irreducibility for Random-Walk MH.** For a random-walk MH algorithm on \\(\\mathbb{R}^d\\) with Gaussian proposal and target density strictly positive and continuous on \\(\\mathbb{R}^d\\), prove that the chain is \\(\\pi\\)-irreducible. Explain how this, together with drift and minorization conditions from Module 5 (see Theorem @thm-geom-ergodicity-drift-minorization), leads to convergence as in Theorem @thm-mh-convergence.\n\n3. **Geometric Ergodicity and Heavy Tails.** Consider a target distribution with polynomially decaying tails and a random-walk MH with Gaussian proposals. Investigate whether the chain satisfies a drift condition that implies geometric ergodicity, and relate your findings to the assumptions of Theorem @thm-geom-ergodicity-drift-minorization.\n\n4. **Diffusion Limit Sketch.** Outline the diffusion limit argument leading to the 0.234 optimal acceptance rate for high-dimensional random-walk MH, identifying the main probabilistic tools used, and connect your argument to Theorem @thm-mh-optimal-scaling.\n\n5. **Practical Tuning.** Discuss heuristic rules for tuning proposal variances in MH in finite dimensions and relate them to the high-dimensional scaling theory and the qualitative conclusions of Theorem @thm-mh-optimal-scaling.\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"toc-depth":3,"css":["../styles.css"],"include-after-body":["../scripts.html"],"output-file":"module06-mh.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.8.26","theme":"cosmo","title":"Module 6: Metropolis–Hastings Algorithm","page-layout":"article"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}