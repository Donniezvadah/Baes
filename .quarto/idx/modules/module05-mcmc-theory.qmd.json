{"title":"Module 5: Markov Chain Monte Carlo (MCMC) Theory","markdown":{"yaml":{"title":"Module 5: Markov Chain Monte Carlo (MCMC) Theory","page-layout":"article"},"headingText":"Module 5: Markov Chain Monte Carlo (MCMC) Theory","containsRefs":false,"markdown":"\n\n\nThis module develops the theory of Markov chains on general state spaces, focusing on invariant distributions, detailed balance, ergodic theorems, and central limit theorems. These results underpin MCMC algorithms used in Bayesian computation.\n\n## 1. Markov Chains on General State Spaces\n\n### 1.1 Transition Kernels\n\nLet $(\\mathsf{X}, \\mathcal{X})$ be a measurable space. A **Markov transition kernel** is a map\n$$\n K: \\mathsf{X} \\times \\mathcal{X} \\to [0,1]\n$$\nsuch that:\n\n1. For each fixed $x \\in \\mathsf{X}$, the map $A \\mapsto K(x, A)$ is a probability measure on $(\\mathsf{X}, \\mathcal{X})$.\n2. For each fixed $A \\in \\mathcal{X}$, the map $x \\mapsto K(x, A)$ is $\\mathcal{X}$-measurable.\n\n### 1.2 Markov Chain Definition\n\nA sequence of random variables $(X_n)_{n \\ge 0}$ taking values in $\\mathsf{X}$ is a **Markov chain** with kernel $K$ if\n$$\n \\mathbb{P}(X_{n+1} \\in A \\mid X_0, \\dots, X_n) = K(X_n, A)\n$$\nfor all $n$ and $A \\in \\mathcal{X}$, almost surely.\n\n## 2. Invariant Distributions and Detailed Balance\n\n### Definition 5.1 (Invariant Distribution) {#def-invariant-distribution}\n\nA probability measure $\\pi$ on $(\\mathsf{X}, \\mathcal{X})$ is **invariant** for $K$ if\n$$\n \\pi(A) = \\int_\\mathsf{X} K(x, A)\\, \\pi(dx), \\quad \\forall A \\in \\mathcal{X}.\n$$\n\n### Definition 5.2 (Detailed Balance and Reversibility) {#def-detailed-balance}\n\nWe say $K$ satisfies **detailed balance** with respect to $\\pi$ if, for all measurable sets $A, B \\in \\mathcal{X}$,\n$$\n \\int_A \\pi(dx) K(x, B) = \\int_B \\pi(dx) K(x, A).\n$$\nEquivalently, in kernel form,\n$$\n \\pi(dx) K(x, dy) = \\pi(dy) K(y, dx).\n$$\n\n### Lemma 5.3 (Detailed Balance Implies Invariance) {#lem-detailed-balance-invariance}\n\nIf $K$ satisfies detailed balance with respect to $\\pi$, then $\\pi$ is invariant for $K$.\n\n*Proof:* By detailed balance,\n$$\n \\int_A \\pi(dx) = \\int_A \\pi(dx) K(x, \\mathsf{X}) = \\int_\\mathsf{X} \\pi(dx) K(x, A)\n$$\nfor all measurable $A \\in \\mathcal{X}$, where we used that $K(x, \\mathsf{X}) = 1$ for all $x$. This is exactly the invariance condition\n$$\n \\pi(A) = \\int_\\mathsf{X} K(x, A) \\, \\pi(dx), \\quad \\forall A \\in \\mathcal{X},\n$$\nas in Definition @def-invariant-distribution. Hence $\\pi$ is invariant for $K$. $\\square$\n\n### 2.1 Reversibility\n\nIf $K$ satisfies detailed balance with $\\pi$, then the Markov chain is **reversible** with respect to $\\pi$; the time-reversed chain has the same transition probabilities.\n\n## 3. Ergodicity and Convergence\n\n### 3.1 Irreducibility and Recurrence\n\nWe adopt the standard framework of Harris chains.\n\n- **Irreducibility:** There exists a nontrivial measure $\\varphi$ on $(\\mathsf{X}, \\mathcal{X})$ such that for each $A \\in \\mathcal{X}$ with $\\varphi(A) > 0$ and each $x \\in \\mathsf{X}$, there exists $n$ with $K^n(x, A) > 0$.\n- **Harris recurrence:** The chain visits every set of positive $\\varphi$-measure infinitely often with probability 1.\n\n### Theorem 5.4 (Ergodic Theorem for Markov Chains) {#thm-ergodic-theorem}\n\nLet $(X_n)$ be an irreducible, aperiodic, positive Harris recurrent Markov chain with invariant distribution $\\pi$. For any integrable function $f: \\mathsf{X} \\to \\mathbb{R}$,\n$$\n \\frac{1}{n} \\sum_{k=1}^n f(X_k) \\to \\int f\\, d\\pi \\quad \\text{almost surely as } n \\to \\infty.\n$$\n\n*Proof sketch:* Under irreducibility, aperiodicity, and positive Harris recurrence, there exists a unique invariant distribution $\\pi$, and the chain can be represented in terms of **regeneration times** (e.g., via Nummelin splitting). One constructs i.i.d. regeneration cycles whose lengths have finite mean and shows that\n$$\n \\frac{1}{n} \\sum_{k=1}^n f(X_k)\n$$\ncan be decomposed into an average over cycles plus a negligible boundary term. The strong law of large numbers for i.i.d. cycles then implies convergence of the time average to the space average $\\int f d\\pi$. See, for example, Meyn & Tweedie for a full proof in the general state-space setting. $\\square$\n\n### 3.2 Drift and Minorization Conditions\n\nTo obtain quantitative convergence rates, we use drift and minorization.\n\n- **Drift condition:** There exist a function $V: \\mathsf{X} \\to [1, \\infty)$, constants $\\lambda < 1$, $b < \\infty$, and a small set $C$ such that\n  $$\n   K V(x) := \\int V(y) K(x, dy) \\le \\lambda V(x) + b \\mathbf{1}_C(x) \\quad \\forall x.\n  $$\n\n- **Minorization condition:** There exist $\\varepsilon>0$, a probability measure $\\nu$, and a small set $C$ such that for all $x \\in C$ and $A \\in \\mathcal{X}$,\n  $$\n   K(x, A) \\ge \\varepsilon \\nu(A).\n  $$\n\n### Theorem 5.5 (Geometric Ergodicity via Drift and Minorization) {#thm-geom-ergodicity-drift-minorization}\n\nIf a Markov chain satisfies a suitable drift condition and minorization condition, then it is geometrically ergodic: there exist constants $M < \\infty$ and $\\rho \\in (0,1)$ such that\n$$\n \\| K^n(x, \\cdot) - \\pi(\\cdot) \\|_{\\text{TV}} \\le M V(x) \\rho^n, \\quad \\forall n, x.\n$$\n\n*Proof sketch:* The drift condition implies that, away from a small set $C$, the chain tends to move towards regions where $V$ is smaller on average, preventing escape to infinity. The minorization condition on $C$ ensures that whenever the chain enters $C$, it has a uniform chance (bounded away from zero) to \"forget\" its past by coupling to a fixed reference measure $\\nu$. Combining these, one constructs regeneration times with geometrically decaying tails and shows that the total variation distance between $K^n(x, \\cdot)$ and $\\pi$ contracts at a geometric rate controlled by $\\rho$. This is formalized using Foster–Lyapunov criteria and renewal theory; see standard references on geometric ergodicity for details. $\\square$\n\n## 4. Central Limit Theorems for Markov Chains\n\n### Theorem 5.6 (CLT for Markov Chains) {#thm-mcmc-clt}\n\nLet $(X_n)$ be a geometrically ergodic Markov chain with invariant distribution $\\pi$, and let $f: \\mathsf{X} \\to \\mathbb{R}$ satisfy suitable moment and regularity conditions (e.g., $f \\in L^{2+\\delta}(\\pi)$ and a drift condition). Then\n$$\n \\sqrt{n}\\Big( \\frac{1}{n} \\sum_{k=1}^n f(X_k) - \\pi f \\Big) \\overset{d}{\\to} N(0, \\sigma_f^2),\n$$\nwhere\n$$\n \\sigma_f^2 = \\operatorname{Var}_\\pi(f(X_0)) + 2 \\sum_{k=1}^\\infty \\operatorname{Cov}_\\pi(f(X_0), f(X_k)).\n$$\n\n*Proof sketch:* One classical route (Gordin's method) writes the centered function $f - \\pi f$ as a **coboundary plus a remainder**,\n$$\n f(X_k) - \\pi f\n  = M_k - M_{k-1} + R_k,\n$$\nwhere $(M_k)$ is a martingale adapted to the Markov chain filtration and the remainder $R_k$ is negligible in the sense that its contribution to the normalized sum vanishes. Geometric ergodicity and moment conditions ensure that the remainder term is small and that the martingale increments have finite second moments. Applying the martingale central limit theorem to the partial sums of $M_k - M_{k-1}$ yields the stated CLT with asymptotic variance\n$$\n \\sigma_f^2 = \\operatorname{Var}_\\pi(f(X_0)) + 2 \\sum_{k=1}^\\infty \\operatorname{Cov}_\\pi(f(X_0), f(X_k)),\n$$\nwhich is finite under the assumed conditions. Alternative proofs use spectral theory when the chain is reversible.\n\n### 4.1 Asymptotic Variance and Monte Carlo Error\n\nThe asymptotic variance $\\sigma_f^2$ determines the Monte Carlo error of ergodic averages. High autocorrelation increases $\\sigma_f^2$ and thus decreases efficiency.\n\n## 5. Relevance to Bayesian Computation\n\nIn Bayesian computation, we typically design $K$ to have invariant distribution equal to the posterior $\\pi$. The theory above justifies:\n\n- the use of ergodic averages to estimate posterior expectations,\n- assessment of convergence and mixing via geometric ergodicity,\n- construction of Monte Carlo standard errors via CLTs.\n\n## 6. Problem Set 5 (Representative Problems)\n\n1. **Detailed Balance and Invariance.** Prove Lemma @lem-detailed-balance-invariance in full measure-theoretic generality, carefully handling $\\sigma$-algebras and integrals.\n\n2. **Simple Geometric Ergodicity Check.** Consider a random-walk Metropolis chain on $\\mathbb{R}$ with Gaussian proposal and Gaussian target. Show that it satisfies a drift condition and deduce geometric ergodicity using Theorem @thm-geom-ergodicity-drift-minorization.\n\n3. **Non-Geometric Ergodicity Example.** Construct or study a heavy-tailed target distribution for which the corresponding random-walk Metropolis chain is not geometrically ergodic. Explain how failure of the assumptions of Theorem @thm-geom-ergodicity-drift-minorization manifests in this example.\n\n4. **CLT Verification.** For a reversible Markov chain with compact state space and continuous transition density, outline a proof of Theorem @thm-mcmc-clt using spectral decomposition.\n\n5. **Asymptotic Variance Estimation.** Describe how to estimate $\\sigma_f^2$ from a finite MCMC sample using batch means or spectral variance estimators, and discuss consistency of these estimators in light of Theorem @thm-mcmc-clt.\n","srcMarkdownNoYaml":"\n\n# Module 5: Markov Chain Monte Carlo (MCMC) Theory\n\nThis module develops the theory of Markov chains on general state spaces, focusing on invariant distributions, detailed balance, ergodic theorems, and central limit theorems. These results underpin MCMC algorithms used in Bayesian computation.\n\n## 1. Markov Chains on General State Spaces\n\n### 1.1 Transition Kernels\n\nLet $(\\mathsf{X}, \\mathcal{X})$ be a measurable space. A **Markov transition kernel** is a map\n$$\n K: \\mathsf{X} \\times \\mathcal{X} \\to [0,1]\n$$\nsuch that:\n\n1. For each fixed $x \\in \\mathsf{X}$, the map $A \\mapsto K(x, A)$ is a probability measure on $(\\mathsf{X}, \\mathcal{X})$.\n2. For each fixed $A \\in \\mathcal{X}$, the map $x \\mapsto K(x, A)$ is $\\mathcal{X}$-measurable.\n\n### 1.2 Markov Chain Definition\n\nA sequence of random variables $(X_n)_{n \\ge 0}$ taking values in $\\mathsf{X}$ is a **Markov chain** with kernel $K$ if\n$$\n \\mathbb{P}(X_{n+1} \\in A \\mid X_0, \\dots, X_n) = K(X_n, A)\n$$\nfor all $n$ and $A \\in \\mathcal{X}$, almost surely.\n\n## 2. Invariant Distributions and Detailed Balance\n\n### Definition 5.1 (Invariant Distribution) {#def-invariant-distribution}\n\nA probability measure $\\pi$ on $(\\mathsf{X}, \\mathcal{X})$ is **invariant** for $K$ if\n$$\n \\pi(A) = \\int_\\mathsf{X} K(x, A)\\, \\pi(dx), \\quad \\forall A \\in \\mathcal{X}.\n$$\n\n### Definition 5.2 (Detailed Balance and Reversibility) {#def-detailed-balance}\n\nWe say $K$ satisfies **detailed balance** with respect to $\\pi$ if, for all measurable sets $A, B \\in \\mathcal{X}$,\n$$\n \\int_A \\pi(dx) K(x, B) = \\int_B \\pi(dx) K(x, A).\n$$\nEquivalently, in kernel form,\n$$\n \\pi(dx) K(x, dy) = \\pi(dy) K(y, dx).\n$$\n\n### Lemma 5.3 (Detailed Balance Implies Invariance) {#lem-detailed-balance-invariance}\n\nIf $K$ satisfies detailed balance with respect to $\\pi$, then $\\pi$ is invariant for $K$.\n\n*Proof:* By detailed balance,\n$$\n \\int_A \\pi(dx) = \\int_A \\pi(dx) K(x, \\mathsf{X}) = \\int_\\mathsf{X} \\pi(dx) K(x, A)\n$$\nfor all measurable $A \\in \\mathcal{X}$, where we used that $K(x, \\mathsf{X}) = 1$ for all $x$. This is exactly the invariance condition\n$$\n \\pi(A) = \\int_\\mathsf{X} K(x, A) \\, \\pi(dx), \\quad \\forall A \\in \\mathcal{X},\n$$\nas in Definition @def-invariant-distribution. Hence $\\pi$ is invariant for $K$. $\\square$\n\n### 2.1 Reversibility\n\nIf $K$ satisfies detailed balance with $\\pi$, then the Markov chain is **reversible** with respect to $\\pi$; the time-reversed chain has the same transition probabilities.\n\n## 3. Ergodicity and Convergence\n\n### 3.1 Irreducibility and Recurrence\n\nWe adopt the standard framework of Harris chains.\n\n- **Irreducibility:** There exists a nontrivial measure $\\varphi$ on $(\\mathsf{X}, \\mathcal{X})$ such that for each $A \\in \\mathcal{X}$ with $\\varphi(A) > 0$ and each $x \\in \\mathsf{X}$, there exists $n$ with $K^n(x, A) > 0$.\n- **Harris recurrence:** The chain visits every set of positive $\\varphi$-measure infinitely often with probability 1.\n\n### Theorem 5.4 (Ergodic Theorem for Markov Chains) {#thm-ergodic-theorem}\n\nLet $(X_n)$ be an irreducible, aperiodic, positive Harris recurrent Markov chain with invariant distribution $\\pi$. For any integrable function $f: \\mathsf{X} \\to \\mathbb{R}$,\n$$\n \\frac{1}{n} \\sum_{k=1}^n f(X_k) \\to \\int f\\, d\\pi \\quad \\text{almost surely as } n \\to \\infty.\n$$\n\n*Proof sketch:* Under irreducibility, aperiodicity, and positive Harris recurrence, there exists a unique invariant distribution $\\pi$, and the chain can be represented in terms of **regeneration times** (e.g., via Nummelin splitting). One constructs i.i.d. regeneration cycles whose lengths have finite mean and shows that\n$$\n \\frac{1}{n} \\sum_{k=1}^n f(X_k)\n$$\ncan be decomposed into an average over cycles plus a negligible boundary term. The strong law of large numbers for i.i.d. cycles then implies convergence of the time average to the space average $\\int f d\\pi$. See, for example, Meyn & Tweedie for a full proof in the general state-space setting. $\\square$\n\n### 3.2 Drift and Minorization Conditions\n\nTo obtain quantitative convergence rates, we use drift and minorization.\n\n- **Drift condition:** There exist a function $V: \\mathsf{X} \\to [1, \\infty)$, constants $\\lambda < 1$, $b < \\infty$, and a small set $C$ such that\n  $$\n   K V(x) := \\int V(y) K(x, dy) \\le \\lambda V(x) + b \\mathbf{1}_C(x) \\quad \\forall x.\n  $$\n\n- **Minorization condition:** There exist $\\varepsilon>0$, a probability measure $\\nu$, and a small set $C$ such that for all $x \\in C$ and $A \\in \\mathcal{X}$,\n  $$\n   K(x, A) \\ge \\varepsilon \\nu(A).\n  $$\n\n### Theorem 5.5 (Geometric Ergodicity via Drift and Minorization) {#thm-geom-ergodicity-drift-minorization}\n\nIf a Markov chain satisfies a suitable drift condition and minorization condition, then it is geometrically ergodic: there exist constants $M < \\infty$ and $\\rho \\in (0,1)$ such that\n$$\n \\| K^n(x, \\cdot) - \\pi(\\cdot) \\|_{\\text{TV}} \\le M V(x) \\rho^n, \\quad \\forall n, x.\n$$\n\n*Proof sketch:* The drift condition implies that, away from a small set $C$, the chain tends to move towards regions where $V$ is smaller on average, preventing escape to infinity. The minorization condition on $C$ ensures that whenever the chain enters $C$, it has a uniform chance (bounded away from zero) to \"forget\" its past by coupling to a fixed reference measure $\\nu$. Combining these, one constructs regeneration times with geometrically decaying tails and shows that the total variation distance between $K^n(x, \\cdot)$ and $\\pi$ contracts at a geometric rate controlled by $\\rho$. This is formalized using Foster–Lyapunov criteria and renewal theory; see standard references on geometric ergodicity for details. $\\square$\n\n## 4. Central Limit Theorems for Markov Chains\n\n### Theorem 5.6 (CLT for Markov Chains) {#thm-mcmc-clt}\n\nLet $(X_n)$ be a geometrically ergodic Markov chain with invariant distribution $\\pi$, and let $f: \\mathsf{X} \\to \\mathbb{R}$ satisfy suitable moment and regularity conditions (e.g., $f \\in L^{2+\\delta}(\\pi)$ and a drift condition). Then\n$$\n \\sqrt{n}\\Big( \\frac{1}{n} \\sum_{k=1}^n f(X_k) - \\pi f \\Big) \\overset{d}{\\to} N(0, \\sigma_f^2),\n$$\nwhere\n$$\n \\sigma_f^2 = \\operatorname{Var}_\\pi(f(X_0)) + 2 \\sum_{k=1}^\\infty \\operatorname{Cov}_\\pi(f(X_0), f(X_k)).\n$$\n\n*Proof sketch:* One classical route (Gordin's method) writes the centered function $f - \\pi f$ as a **coboundary plus a remainder**,\n$$\n f(X_k) - \\pi f\n  = M_k - M_{k-1} + R_k,\n$$\nwhere $(M_k)$ is a martingale adapted to the Markov chain filtration and the remainder $R_k$ is negligible in the sense that its contribution to the normalized sum vanishes. Geometric ergodicity and moment conditions ensure that the remainder term is small and that the martingale increments have finite second moments. Applying the martingale central limit theorem to the partial sums of $M_k - M_{k-1}$ yields the stated CLT with asymptotic variance\n$$\n \\sigma_f^2 = \\operatorname{Var}_\\pi(f(X_0)) + 2 \\sum_{k=1}^\\infty \\operatorname{Cov}_\\pi(f(X_0), f(X_k)),\n$$\nwhich is finite under the assumed conditions. Alternative proofs use spectral theory when the chain is reversible.\n\n### 4.1 Asymptotic Variance and Monte Carlo Error\n\nThe asymptotic variance $\\sigma_f^2$ determines the Monte Carlo error of ergodic averages. High autocorrelation increases $\\sigma_f^2$ and thus decreases efficiency.\n\n## 5. Relevance to Bayesian Computation\n\nIn Bayesian computation, we typically design $K$ to have invariant distribution equal to the posterior $\\pi$. The theory above justifies:\n\n- the use of ergodic averages to estimate posterior expectations,\n- assessment of convergence and mixing via geometric ergodicity,\n- construction of Monte Carlo standard errors via CLTs.\n\n## 6. Problem Set 5 (Representative Problems)\n\n1. **Detailed Balance and Invariance.** Prove Lemma @lem-detailed-balance-invariance in full measure-theoretic generality, carefully handling $\\sigma$-algebras and integrals.\n\n2. **Simple Geometric Ergodicity Check.** Consider a random-walk Metropolis chain on $\\mathbb{R}$ with Gaussian proposal and Gaussian target. Show that it satisfies a drift condition and deduce geometric ergodicity using Theorem @thm-geom-ergodicity-drift-minorization.\n\n3. **Non-Geometric Ergodicity Example.** Construct or study a heavy-tailed target distribution for which the corresponding random-walk Metropolis chain is not geometrically ergodic. Explain how failure of the assumptions of Theorem @thm-geom-ergodicity-drift-minorization manifests in this example.\n\n4. **CLT Verification.** For a reversible Markov chain with compact state space and continuous transition density, outline a proof of Theorem @thm-mcmc-clt using spectral decomposition.\n\n5. **Asymptotic Variance Estimation.** Describe how to estimate $\\sigma_f^2$ from a finite MCMC sample using batch means or spectral variance estimators, and discuss consistency of these estimators in light of Theorem @thm-mcmc-clt.\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"toc-depth":3,"css":["../styles.css"],"include-after-body":["../scripts.html"],"output-file":"module05-mcmc-theory.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.8.26","theme":"cosmo","title":"Module 5: Markov Chain Monte Carlo (MCMC) Theory","page-layout":"article"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}